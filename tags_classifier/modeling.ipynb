{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cPickle\n",
    "import heapq\n",
    "from bisect import bisect_left\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('../data/joint_raw.csv', sep='\\t', encoding='utf-8')\n",
    "data_norm = pd.read_csv('../data/joint_norm.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_similar_tags(t):\n",
    "    if t == u'неисполнение решений суда':\n",
    "        return u'неисполнение решения суда'\n",
    "    elif t == u'вывоз детей за границу без разрешения отца':\n",
    "        return u'вывоз ребёнка за границу без разрешения отца'\n",
    "    elif t == u'убийство собак':\n",
    "        return u'убийство собаки'\n",
    "    elif t == u'ответственность за неисполнения решения суда':\n",
    "        return u'ответственность за неисполнение решения суда'\n",
    "    elif t == u'долги по налогам':\n",
    "        return u'долг по налогам'\n",
    "    elif t == u'задолженность по жкх':\n",
    "        return u'задолженность ЖКХ'\n",
    "    elif t == u'дарственное на квартиру':\n",
    "        return u'дарственная на квартиру'\n",
    "    elif t == u'задолженности по кредитам':\n",
    "        return u'задолженность по кредиту'\n",
    "    elif t == u'ДТП с пострадавшим':\n",
    "        return u'ДТП с пострадавшими'\n",
    "    elif t == u'квартиры по военной ипотеке':\n",
    "        return u'квартира по военной ипотеке'\n",
    "    elif t == u'долг судебным приставам':\n",
    "        return u'долги перед судебными приставами'\n",
    "    elif t == u'эмансипация несовершеннолетней':\n",
    "        return u'эмансипация несовершеннолетнего'\n",
    "    elif t == u'долги по алиментам':\n",
    "        return u'долг по алиментам'\n",
    "    elif t == u'выплаты за третьего ребенка':\n",
    "        return u'выплаты на третьего ребенка'\n",
    "    elif t == u'документы для продажи квартиры':\n",
    "        return u'документы при продаже квартиры'\n",
    "    elif t == u'запрет выезда за границу':\n",
    "        return u'запреты на выезд за границу'\n",
    "    elif t == u'отказ от детей':\n",
    "        return u'отказ от ребенка'\n",
    "    elif t == u'налог с продажи дома':\n",
    "        return u'налоги при продаже дома'\n",
    "    elif t == u'возврат денег за неоказанные услуги':\n",
    "        return u'возврат денег за неоказанную услугу'\n",
    "    elif t == u'просрочены права':\n",
    "        return u'просроченные права'\n",
    "    elif t == u'займы под материнский капитал':\n",
    "        return u'займ под материнский капитал'\n",
    "    elif t == u'права несовершеннолетних детей':\n",
    "        return u'права несовершеннолетнего ребенка'\n",
    "    elif t == u'налоговый вычет при ипотеке':\n",
    "        return u'налоговый вычет по ипотеке'\n",
    "    elif t == u'протокол административного правонарушения':\n",
    "        return u'протокол об административном правонарушении'\n",
    "    elif t == u'отработка при увольнении':\n",
    "        return u'отработка после увольнения'\n",
    "    elif t == u'обременение земельного участка':\n",
    "        return u'обременения земельного участка'\n",
    "    elif t == u'публичные оскорбления':\n",
    "        return u'публичное оскорбление'\n",
    "    elif t == u'долги по исполнительному листу':\n",
    "        return u'долги по исполнительным листам'\n",
    "    elif t == u'удержание по исполнительному листу':\n",
    "        return u'удержание по исполнительным листам'\n",
    "    elif t == u'пропущены сроки вступления в наследство':\n",
    "        return u'пропущенный срок вступления в наследство'\n",
    "    elif t == u'несанкционированные свалки':\n",
    "        return u'несанкционированная свалка'\n",
    "    elif t == u'кража из магазина':\n",
    "        return u'кража в магазине'\n",
    "    elif t == u'нарушения авторского права':\n",
    "        return u'нарушение авторского права'\n",
    "    else:\n",
    "        return t\n",
    "\n",
    "# data_raw.loc[:,'tag'] = data_raw.tag.apply(merge_similar_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data_norm.text.values\n",
    "y = data_norm.tag.values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags_raw = data_raw.tag.unique()\n",
    "tags_norm = data_norm.tag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cPickle.dump(tags_raw, open('../data/tags_raw.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "возврат долга по расписке\n",
      "возврат долга без расписки\n",
      "договор аренды транспортного средства без экипажа\n",
      "договор аренды транспортного средства с экипажем\n",
      "сбил пешехода на пешеходном переходе\n",
      "сбил пешехода вне пешеходного перехода\n"
     ]
    }
   ],
   "source": [
    "print len(tags_raw) - len(tags_norm)\n",
    "for t in tags_norm:\n",
    "    tt = data_raw[data_norm.tag == t].tag.unique()\n",
    "    if len(tt) > 1:\n",
    "        for _t in tt:\n",
    "            print _t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_raw.to_csv('../data/joint_raw.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_norm_to_raw = []\n",
    "for t in tags_norm:\n",
    "    if t == u'возврат долг расписка':\n",
    "        tags_norm_to_raw.append([u'возврат долга по расписке', u'возврат долга без расписки'])\n",
    "    elif t == u'договор аренда транспортный средство экипаж':\n",
    "        tags_norm_to_raw.append([u'договор аренды транспортного средства без экипажа',\n",
    "                u'договор аренды транспортного средства с экипажем'])\n",
    "    elif t == u'сбить пешеход пешеходный переход':\n",
    "        tags_norm_to_raw.append([u'сбил пешехода на пешеходном переходе', \n",
    "                                 u'сбил пешехода вне пешеходного перехода'])\n",
    "    else:\n",
    "        tags_norm_to_raw.append(data_raw.tag[data_norm.tag == t].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cPickle.dump(tags_norm, open('../data/tags_norm.p', 'wb'))\n",
    "# cPickle.dump(tags_norm_to_raw, open('../data/tags_norm_to_raw.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "def normalize(s):\n",
    "    return ' '.join(map(lambda w: morph.parse(w)[0].normal_form, tokenizer.tokenize(s)))\n",
    "\n",
    "def get_normalized_tokens(s):\n",
    "    return map(lambda w: morph.parse(w)[0].normal_form, tokenizer.tokenize(s))\n",
    "\n",
    "def remove_minor_pos(s):\n",
    "    return ' '.join(filter(lambda w: morph.parse(w)[0].tag.POS not in ['PREP', 'CONJ', 'PRCL', 'INTJ'], tokenizer.tokenize(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синонимы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.8 s, sys: 112 ms, total: 25.9 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tags_synonyms = []\n",
    "with open('../data/syn.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = map(lambda l: l.decode('utf-8'), lines)\n",
    "    lines.sort()\n",
    "    for tag in tags_norm:\n",
    "        tag_syns = []\n",
    "        for word in tag.split(' '):\n",
    "            idx = bisect_left(lines, word+'|')\n",
    "            line = lines[idx]\n",
    "            if line.startswith(word+'|'):\n",
    "                tag_syns += get_normalized_tokens(line.split('|')[1])\n",
    "        tags_synonyms.append(tag_syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump(tags_synonyms, open('../data/tags_synonyms.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags_synonyms = cPickle.load(open('../data/tags_synonyms.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неудачные веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 19s, sys: 1.44 s, total: 21min 21s\n",
      "Wall time: 21min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for tag_idx in xrange(len(tags_norm)):\n",
    "    tag = tags_norm[tag_idx]\n",
    "    for word_idx in xrange(len(tag)):\n",
    "        w1 = np.array(map(lambda text: w in text, X_train[y_train == t])).sum() / float((y_train == t).sum())\n",
    "        w2 = np.array(map(lambda text: w in text, X_train[y_train != t])).sum() / float((y_train != t).sum())\n",
    "        tag[word_idx] = (tag[word_idx], w1/w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_n_tags(text, n):\n",
    "    predicted_n = [(-1, -1)] * n\n",
    "    heapq.heapify(predicted_n)\n",
    "    for tag in tags_norm:\n",
    "        trust_level = 0.\n",
    "        for word, weight in tag:\n",
    "            if word in text:\n",
    "                trust_level += weight\n",
    "        heapq.heappushpop(predicted_n, (trust_level, ' '.join(zip(*tag)[0])))\n",
    "    return predicted_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "print y_train[idx]\n",
    "print X_train[idx]\n",
    "predicted_3 = predict_n_tags(X_train[idx], 3)\n",
    "for pair in predicted_3:\n",
    "    print u'{0} - {1}'.format(pair[1], pair[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Counts the number of words from <words>, that appear in <text>\n",
    "def count_entries(words, text):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in text:\n",
    "            count += 0.5\n",
    "    return count\n",
    "\n",
    "PAIR_WEIGHT = 2\n",
    "def count_entries2(words, text):\n",
    "    count = 0\n",
    "    words = words.split(' ')\n",
    "    for i in range(len(words)-1):\n",
    "        if words[i] in text:\n",
    "            count += 1\n",
    "            pair = ' '.join((words[i], words[i+1]))\n",
    "            if pair in text:\n",
    "                count += PAIR_WEIGHT\n",
    "    if words[-1] in text:\n",
    "        count += 1\n",
    "    return count\n",
    "def count_part_entries2(words, text, part_size, weight, pair_weight):\n",
    "    count = 0\n",
    "    words = words.split(' ')\n",
    "    words = map(lambda w: w[:part_size], words)\n",
    "    text = ' '.join(map(lambda w: w[:part_size], text.split(' ')))\n",
    "    for i in range(len(words)-1):\n",
    "        if words[i] in text:\n",
    "            count += weight\n",
    "            pair = ' '.join((words[i], words[i+1]))\n",
    "            if pair in text:\n",
    "                count += pair_weight * weight\n",
    "    if words[-1] in text:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns <num_tags> the most suitable tags for <text>\n",
    "def get_top_tags(text, tags, num_tags, part_size, two_counts, part_weight=1, pair_weight=0):\n",
    "    similarities = []\n",
    "    for tag in tags:\n",
    "        if two_counts:\n",
    "            similarities.append(count_entries2(tag, text) / float(len(tag.split(' '))))\n",
    "            similarities[-1] += count_part_entries2(tag, text, part_size, part_weight, pair_weight) / float(len(tag.split(' ')))\n",
    "        else:\n",
    "            similarities.append(count_part_entries2(tag, text, part_size, part_weight, pair_weight) / float(len(tag.split(' '))))\n",
    "#         similarities[-1] += count_part_entries2(tag, text, 5) / float(len(tag.split(PAIR_WEIGHT ' ')))\n",
    "#     for tag, syns in zip(tags, tags_synonyms):\n",
    "#         similarities.append(count_entries2(tag, text) / float(len(tag)))\n",
    "#         similarities[-1] += count_entries(syns, text) / float(len(tag))\n",
    "    result = []\n",
    "    for _ in range(num_tags):\n",
    "        idx = np.argmax(similarities)\n",
    "        result.append((tags[idx], similarities[idx]))\n",
    "        similarities[idx] = 0.\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 False 0\n",
      "0.314354496647\n",
      "4 False 1\n",
      "0.314354496647\n",
      "4 False 2\n",
      "0.314354496647\n",
      "5 False 0\n",
      "0.380786793787\n",
      "5 False 1\n",
      "0.380786793787\n",
      "5 False 2\n",
      "0.380786793787\n",
      "6 False 0\n",
      "0.409063986702\n",
      "6 False 1\n",
      "0.409063986702\n",
      "6 False 2\n",
      "0.409063986702\n",
      "CPU times: user 4h 26min 3s, sys: 27.5 s, total: 4h 26min 31s\n",
      "Wall time: 4h 25min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_, X_small, _, y_small = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "num_tested = len(X_small)\n",
    "for part_size in (4,5,6):\n",
    "    for two_counts in (False,):\n",
    "        if two_counts:\n",
    "            for part_weight in (0.5, 1., 1.5):\n",
    "                num_guessed = 0\n",
    "                for i in xrange(num_tested):\n",
    "                    top3 = get_top_tags(X_small[i], tags_norm, 3, part_size, two_counts, part_weight)\n",
    "                    if y_small[i] in zip(*top3)[0]:\n",
    "                        num_guessed += 1\n",
    "                acc = num_guessed / float(num_tested)\n",
    "                print part_size, two_counts, part_weight\n",
    "                print acc\n",
    "        else:\n",
    "            for pair_weight in (0,1,2):\n",
    "                num_guessed = 0\n",
    "                for i in xrange(num_tested):\n",
    "                    top3 = get_top_tags(X_small[i], tags_norm, 3, part_size, two_counts)\n",
    "                    if y_small[i] in zip(*top3)[0]:\n",
    "                        num_guessed += 1\n",
    "                acc = num_guessed / float(num_tested)\n",
    "                print part_size, two_counts, pair_weight\n",
    "                print acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.481467329003\n",
      "0.489491784486\n",
      "0.510126098586\n",
      "Avg. accuracy: 0.493695070692\n",
      "CPU times: user 4min 27s, sys: 456 ms, total: 4min 27s\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "                \n",
    "# X_small = X\n",
    "# y_small = y\n",
    "accuracies = []\n",
    "for j in range(3):\n",
    "    _, X_small, _, y_small = train_test_split(X, y, test_size=0.01)\n",
    "    num_guessed = 0\n",
    "    num_tested = len(X_small)\n",
    "    for i in xrange(num_tested):\n",
    "        top3 = get_top_tags(X_small[i], tags_norm, 3, 6, False, 1, 1)\n",
    "        if y_small[i] in zip(*top3)[0]:\n",
    "            num_guessed += 1\n",
    "    acc = num_guessed / float(num_tested)\n",
    "    print acc\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print 'Avg. accuracy: {0}'.format(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_sorted = data_tagged.tag.value_counts().index.values\n",
    "tag_encoder = dict(zip(tags_sorted, range(len(tags_sorted))))\n",
    "y_tag_encoded = np.array(map(lambda c: tag_encoder[c], y_tag))\n",
    "y_tag_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n        lowercase=False, max_df=0.7, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True...s=50, n_estimators=10, n_neighbors=5,\n     radius=1.0, radius_cutoff_ratio=0.9, random_state=None))]) does not.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-61d7d935b625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSHForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ])\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/metrics/scorer.pyc\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    244\u001b[0m         raise TypeError(\n\u001b[1;32m    245\u001b[0m             \u001b[0;34m\"If no scoring is specified, the estimator passed should \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \"have a 'score' method. The estimator %r does not.\" % estimator)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator Pipeline(steps=[('vect', TfidfVectorizer(analyzer=u'word', binary=True, decode_error=u'strict',\n        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n        lowercase=False, max_df=0.7, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True...s=50, n_estimators=10, n_neighbors=5,\n     radius=1.0, radius_cutoff_ratio=0.9, random_state=None))]) does not."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерим фичи из тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_words = []\n",
    "for tag in tags_norm:\n",
    "    key_words += tag\n",
    "key_words = set(key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] no parameters to be set .........................................\n",
      "[CV] ................ no parameters to be set, score=0.000284 - 1.8min\n",
      "[CV] no parameters to be set .........................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ee4e675fb13e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu\"\\nX_small = X\\ny_small = y\\n# _, X_small, _, y_small = train_test_split(X, y, test_size=0.1)\\npipeline = Pipeline([\\n    ('vect', CountVectorizer(binary=True, lowercase=False, vocabulary=key_words)),\\n    ('clf', SGDClassifier())\\n#     ('clf', LogisticRegression(solver='lbfgs', multi_class='multinomial'))\\n])\\ncross_val_score(pipeline, X_small, y_small, verbose=4, scoring='accuracy').mean()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1433\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[1;32m    164\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.n_iter,\n\u001b[0;32m--> 415\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, n_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    371\u001b[0m             self._fit_multiclass(X, y, alpha=alpha, C=C,\n\u001b[1;32m    372\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                                  sample_weight=sample_weight, n_iter=n_iter)\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             self._fit_binary(X, y, alpha=alpha, C=C,\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36m_fit_multiclass\u001b[0;34m(self, X, y, alpha, C, learning_rate, sample_weight, n_iter)\u001b[0m\n\u001b[1;32m    455\u001b[0m                                 \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                 sample_weight)\n\u001b[0;32m--> 457\u001b[0;31m             for i in range(len(self.classes_)))\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.pyc\u001b[0m in \u001b[0;36mfit_binary\u001b[0;34m(est, i, X, y, alpha, C, learning_rate, n_iter, pos_weight, neg_weight, sample_weight)\u001b[0m\n\u001b[1;32m    276\u001b[0m                          \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                          \u001b[0mlearning_rate_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                          est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_small = X\n",
    "y_small = y\n",
    "# _, X_small, _, y_small = train_test_split(X, y, test_size=0.1)\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(binary=True, lowercase=False, vocabulary=key_words)),\n",
    "    ('clf', SGDClassifier())\n",
    "#     ('clf', LogisticRegression(solver='lbfgs', multi_class='multinomial'))\n",
    "])\n",
    "cross_val_score(pipeline, X_small, y_small, verbose=4, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-07983c74b0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnum_tested\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_small\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlshf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_small\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mnum_guessed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_guessed\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/neighbors/approximate.pyc\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    439\u001b[0m             neighs, dists = self._get_candidates(X[[i]], max_depth[i],\n\u001b[1;32m    440\u001b[0m                                                  \u001b[0mbin_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                                                  n_neighbors)\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilya/.virtualenvs/ai-lawyer/local/lib/python2.7/site-packages/sklearn/neighbors/approximate.pyc\u001b[0m in \u001b[0;36m_get_candidates\u001b[0;34m(self, query, max_depth, bin_queries, n_neighbors)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mn_candidates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 candidate_set.update(\n\u001b[0;32m--> 276\u001b[0;31m                     self.original_indices_[i][start:stop].tolist())\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mmax_depth\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "from sklearn.neighbors import LSHForest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "key_words = []\n",
    "for tag in tags_norm:\n",
    "    key_words += tag\n",
    "key_words = set(key_words)    \n",
    "\n",
    "# _, X_small, _, y_small = train_test_split(X, y, test_size=0.1)\n",
    "# pipeline = Pipeline([\n",
    "#     ('vect', CountVectorizer(binary=True, lowercase=False, vocabulary=key_words)),\n",
    "#     ('clf', LSHForest())\n",
    "# #     ('clf', LogisticRegression(solver='lbfgs', multi_class='multinomial'))\n",
    "# ])\n",
    "# cross_val_score(pipeline, X_small, y_small, verbose=4, scoring='accuracy').mean()\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for j in range(3):\n",
    "    _, X_small, _, y_small = train_test_split(X, y, test_size=0.5)\n",
    "    X_small = CountVectorizer(binary=True, lowercase=False, vocabulary=key_words).fit_transform(X_small)\n",
    "    lshf = LSHForest().fit(X_small, y_small)\n",
    "    num_guessed = 0\n",
    "    num_tested = X_small.shape[0]\n",
    "    for i in xrange(num_tested):\n",
    "        if i == lshf.kneighbors(X_small[i], 1)[1][0]:\n",
    "            num_guessed += 1\n",
    "    acc = num_guessed / float(num_tested)\n",
    "    print acc\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print 'Avg. accuracy: {0}'.format(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кредитов\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class Porter:\n",
    "\tPERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "\tREFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "\tADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "\tPARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "\tVERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "\tNOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "\tRVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "\tDERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "\tDER = re.compile(u\"ость?$\")\n",
    "\tSUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "\tI = re.compile(u\"и$\")\n",
    "\tP = re.compile(u\"ь$\")\n",
    "\tNN = re.compile(u\"нн$\")\n",
    "\n",
    "\tdef stem(word):\n",
    "\t\tword = word.lower()\n",
    "\t\tword = word.replace(u'ё', u'е')\n",
    "\t\tm = re.match(Porter.RVRE, word)\n",
    "\t\tif m.groups():\n",
    "\t\t\tpre = m.group(1)\n",
    "\t\t\trv = m.group(2)\n",
    "\t\t\ttemp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "\t\t\tif temp == rv:\n",
    "\t\t\t\trv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "\t\t\t\ttemp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "\t\t\t\tif temp != rv:\n",
    "\t\t\t\t\trv = temp\n",
    "\t\t\t\t\trv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttemp = Porter.VERB.sub('', rv, 1)\n",
    "\t\t\t\t\tif temp == rv:\n",
    "\t\t\t\t\t\trv = Porter.NOUN.sub('', rv, 1)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\trv = temp\n",
    "\t\t\telse:\n",
    "\t\t\t\trv = temp\n",
    "\t\t\t\n",
    "\t\t\trv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "\t\t\tif re.match(Porter.DERIVATIONAL, rv):\n",
    "\t\t\t\trv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "\t\t\ttemp = Porter.P.sub('', rv, 1)\n",
    "\t\t\tif temp == rv:\n",
    "\t\t\t\trv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "\t\t\t\trv = Porter.NN.sub(u'н', rv, 1)\n",
    "\t\t\telse:\n",
    "\t\t\t\trv = temp\n",
    "\t\t\tword = pre+rv\n",
    "\t\treturn word\n",
    "\tstem=staticmethod(stem)\n",
    "\t\n",
    "print Porter.stem(u'покупки')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}